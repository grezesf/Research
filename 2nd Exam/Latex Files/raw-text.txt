Second Exam 
Topic: Reservoir Computing, a new paradigm for Neural Networks, and its applications to Natural Language Processing
author: Felix Grezes
advisor: Pr. Andrew Rosenberg
committee: Pr. Liang Huang, Pr. Susan Epstein (CUNY), Pr. Noemie Elhadad (Columbia University)

date: before June 23rd


Introduction (abstract)
    S1: NNs  and RNNs are interesting, but face theoretical and practical difficulties
    S2: RNN are interesting because: dynamical model, biologically inspired...
    S3: Reservoirs can fix these problems
    S4: With this approach, new applications are possible 

History of Neural Networks
        Historical recap and appeal 
    Feed-Forward Networks
        History through decades? all the way back to the 40s?
        Some Theory (Back-prob) 
        Recent accomplishments, notably in NLP
    Recurrent Neural Networks 
        History Existing Models
        Delve deeper into the difficulties 
    
The Reservoir Computing Paradigm
    History: Echo State Networks and Liquid State Machine
    Theory: Give what small results there is.
        
    Applications:
        Non-NLP (Physics, Biology)
        NLP: Mix my own research in?


        

