{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create 1 GMM per TIMIT phone type, fitted only on those phone observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Scykit learn GMM library\n",
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find_phone_index', 'load_phone_file']\n"
     ]
    }
   ],
   "source": [
    "# import custom functions\n",
    "import sys\n",
    "# path to libraries\n",
    "# currently in ../scripts-lib/\n",
    "tool_path = os.path.abspath('..' + os.sep + 'scripts-lib')\n",
    "\n",
    "if tool_path not in sys.path:\n",
    "    sys.path.append(tool_path)\n",
    "import lib_phones as lph\n",
    "\n",
    "# print the loaded functions\n",
    "print dir(lph)[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 ['aa', 'ae', 'ah', 'ao', 'aw', 'ax', 'ax-h', 'axr', 'ay', 'b', 'bcl', 'ch', 'd', 'dcl', 'dh', 'dx', 'eh', 'el', 'em', 'en', 'eng', 'epi', 'er', 'ey', 'f', 'g', 'gcl', 'h#', 'hh', 'hv', 'ih', 'ix', 'iy', 'jh', 'k', 'kcl', 'l', 'm', 'n', 'ng', 'nx', 'ow', 'oy', 'p', 'pau', 'pcl', 'q', 'r', 's', 'sh', 't', 'tcl', 'th', 'uh', 'uw', 'ux', 'v', 'w', 'y', 'z', 'zh']\n"
     ]
    }
   ],
   "source": [
    "# load phone list\n",
    "phone_path = os.path.abspath('../datasets/TIMIT-MFCCs/TIMIT_phone_list.txt')\n",
    "phone_list = lph.load_phone_file(phone_path)\n",
    "print len(phone_list), phone_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working in path : C:\\Users\\FG\\Desktop\\PhD\\Research\\Reservoirs\\datasets\\TIMIT-MFCCs\\dev\n",
      "working on: si1027.mfcc.csv\n",
      "working on: si1105.mfcc.csv\n",
      "working on: si1657.mfcc.csv\n",
      "working on: si1735.mfcc.csv\n",
      "working on: si475.mfcc.csv\n",
      "working on: si648.mfcc.csv\n",
      "working on: sx115.mfcc.csv\n",
      "working on: sx127.mfcc.csv\n",
      "working on: sx205.mfcc.csv\n",
      "working on: sx217.mfcc.csv\n",
      "working on: sx25.mfcc.csv\n",
      "working on: sx295.mfcc.csv\n",
      "working on: sx307.mfcc.csv\n",
      "working on: sx37.mfcc.csv\n",
      "working on: sx385.mfcc.csv\n",
      "working on: sx397.mfcc.csv\n"
     ]
    }
   ],
   "source": [
    "#load mfccs into sklearn observations, each frame is an obs\n",
    "\n",
    "train_TIMIT_dir = os.path.abspath('../datasets/TIMIT-MFCCs/dev')\n",
    "\n",
    "#create individual obs list for each phone type\n",
    "train_phone_obs_dict = {}\n",
    "for phone in phone_list:\n",
    "    train_phone_obs_dict[phone] = []\n",
    "\n",
    "# complete obs \n",
    "train_obs = []\n",
    "train_obs_labels = []\n",
    "\n",
    "# walk the directories\n",
    "for (path, dirs, files) in os.walk(train_TIMIT_dir):\n",
    "    print \"working in path : \" + path\n",
    "\n",
    "    for file in files:\n",
    "        # skip the SA files\n",
    "        #dev, only work on file si1573.mfcc.csv     \"si1573\" in file and\n",
    "        if \".mfcc\" in file  and \"sa\" not in file:\n",
    "            #check if corresponding .phn file exists\n",
    "            if not os.path.exists(path + \"/\" + file[:-8] + \"phn\"):\n",
    "                print path + \"/\" + file[:-8] + \"phn\"\n",
    "                print \"corresponding .phn file does not exist!\"\n",
    "            else:\n",
    "                \n",
    "                print \"working on: \" + file\n",
    "#                 print \"from path : \" + path\n",
    "\n",
    "                # open the files\n",
    "                mfcc_file = open(path + \"/\" + file)\n",
    "                phn_file = open(path + \"/\" + file[:-8] + \"phn\")\n",
    "\n",
    "                # extract phone times\n",
    "                phone_times = []\n",
    "                for phn_line in phn_file:\n",
    "                    phone_times.append(phn_line.split())\n",
    "                # transpose for easier use\n",
    "                phone_times = map(list, zip(*phone_times))\n",
    "\n",
    "                # skip mfcc_file header\n",
    "                next(mfcc_file)\n",
    "\n",
    "                # reset frame count\n",
    "                frame_cnt = 0\n",
    "\n",
    "                # for each line of mfcc_file\n",
    "                for mfcc_line in mfcc_file:\n",
    "\n",
    "                    # increment frame count\n",
    "                    frame_cnt += 1 \n",
    "\n",
    "                    # print \"frame line #:\", frame_cnt \n",
    "\n",
    "                    # frame start time in seconds\n",
    "                    start_t = mfcc_line.split(\";\")[1]\n",
    "\n",
    "                    # create frame (skiping first 2 values, frame_index and frame_time)\n",
    "                    frame = map( float,  mfcc_line.split(\";\")[2:])\n",
    "                    # print numpy.shape(frame)\n",
    "                    # print frame\n",
    "\n",
    "                    # find correspond phoneme and index in the list\n",
    "                    phn_index = lph.find_phone_index(start_t, phone_times, phone_list)\n",
    "\n",
    "                    # add to instances for corresponding \n",
    "                    train_phone_obs_dict[phone_list[phn_index]].append(frame)\n",
    "                    # add to instances\n",
    "                    train_obs.append(frame)\n",
    "                    train_obs_labels.append(phone_list[phn_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smallest phone observations\n",
    "min([len(train_phone_obs_dict[phone]) for phone in phone_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gmm for phone aa\n",
      "training gmm for phone ae\n",
      "training gmm for phone ah\n",
      "training gmm for phone ao\n",
      "training gmm for phone aw\n",
      "training gmm for phone ax\n",
      "training gmm for phone ax-h\n",
      "training gmm for phone axr\n",
      "training gmm for phone ay\n",
      "training gmm for phone b\n",
      "training gmm for phone bcl\n",
      "not enough obs for phone ch\n",
      "training gmm for phone d\n",
      "training gmm for phone dcl\n",
      "training gmm for phone dh\n",
      "training gmm for phone dx\n",
      "training gmm for phone eh\n",
      "training gmm for phone el\n",
      "training gmm for phone em\n",
      "not enough obs for phone en\n",
      "not enough obs for phone eng\n",
      "training gmm for phone epi\n",
      "training gmm for phone er\n",
      "training gmm for phone ey\n",
      "training gmm for phone f\n",
      "training gmm for phone g\n",
      "training gmm for phone gcl\n",
      "training gmm for phone h#\n",
      "training gmm for phone hh\n",
      "training gmm for phone hv\n",
      "training gmm for phone ih\n",
      "training gmm for phone ix\n",
      "training gmm for phone iy\n",
      "training gmm for phone jh\n",
      "training gmm for phone k\n",
      "training gmm for phone kcl\n",
      "training gmm for phone l\n",
      "training gmm for phone m\n",
      "training gmm for phone n\n",
      "training gmm for phone ng\n",
      "not enough obs for phone nx\n",
      "training gmm for phone ow\n",
      "training gmm for phone oy\n",
      "training gmm for phone p\n",
      "training gmm for phone pau\n",
      "training gmm for phone pcl\n",
      "training gmm for phone q\n",
      "training gmm for phone r\n",
      "training gmm for phone s\n",
      "training gmm for phone sh\n",
      "training gmm for phone t\n",
      "training gmm for phone tcl\n",
      "training gmm for phone th\n",
      "not enough obs for phone uh\n",
      "training gmm for phone uw\n",
      "training gmm for phone ux\n",
      "training gmm for phone v\n",
      "training gmm for phone w\n",
      "not enough obs for phone y\n",
      "training gmm for phone z\n",
      "not enough obs for phone zh\n"
     ]
    }
   ],
   "source": [
    "# gmm parameters\n",
    "num_components = 10\n",
    "num_iter=2\n",
    "\n",
    "# dictionary containing a gmm for each phone, trained directly on obervation on those phones\n",
    "gmm_dict = dict()\n",
    "\n",
    "# for each phone, build a GMM\n",
    "for phone in phone_list:\n",
    "    \n",
    "    # check if enough observations exist\n",
    "    if len(train_phone_obs_dict[phone]) < num_components:\n",
    "        print \"not enough obs for phone\", phone\n",
    "        pass\n",
    "    else:\n",
    "        print \"training gmm for phone\", phone\n",
    "        g = mixture.GMM(n_components= num_components, n_iter=num_iter) \n",
    "        g.fit(train_phone_obs_dict[phone])\n",
    "        gmm_dict[phone] = g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved unadapted gmm dictionary in  C:\\Users\\FG\\Desktop\\PhD\\Research\\Reservoirs\\datasets\\TIMIT Pickled Data\\TIMIT_gmm_unadapted_dict.pckl\n"
     ]
    }
   ],
   "source": [
    "#save gmm in pickled form\n",
    "import cPickle as pickle\n",
    "\n",
    "# name and location to save in\n",
    "pickle_name = \"TIMIT_gmm_unadapted_dict\" + \".pckl\"\n",
    "pickle_dir = os.path.abspath('..'+ os.sep + 'datasets' + os.sep + 'TIMIT Pickled Data')\n",
    "\n",
    "if not os.path.isdir(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "    \n",
    "pickle.dump( gmm_dict, open( pickle_dir + os.sep + pickle_name, \"wb\") )\n",
    "print \"saved unadapted gmm dictionary in \", pickle_dir + os.sep + pickle_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
